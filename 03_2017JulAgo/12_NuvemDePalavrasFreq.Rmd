---
title: "Palavras frequentes"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

### Critérios informados

```{r, echo=FALSE}
source("..\\02_2017MaiJun\\05_EncodeDecode.R")

if(!require(tm)) { install.packages('tm') }
if(!require(qdap)) { install.packages('qdap') }
if(!require(RWeka)) { install.packages('RWeka') }

if(!require(tidyverse)) { install.packages('tidyverse') }
if(!require(tidytext)) { install.packages('tidytext') }
if(!require(tidyr)) { install.packages('tidyr') }
if(!require(dplyr)) { install.packages('dplyr') }   

if(!require(wordcloud)) { install.packages('wordcloud') }
if(!require(SnowballC)) { install.packages('SnowballC') }
if(!require(stringr)) { install.packages('stringr') }
if(!require(ggplot2)) { install.packages('ggplot2') }
if(!require(gridExtra)) { install.packages('gridExtra') }

# https://rpubs.com/mlmv/swiftkey


# lê arquivo com todos os discursos
ini <- 2003
fim <- 2016
partido <- "PT"

pasta <- "..\\CorporaRDS\\"
arquivo <- paste0("corpora_", partido, "_", ini, "_", fim, "_limpo.rds")
lista <- readRDS(paste0(pasta, arquivo))
docs <- lista[[1]]
tfq  <- lista[[2]]
bigramas <- lista[[3]]

print(sprintf("Partido: %s (%d - %d)", partido, ini, fim))
print(sprintf("Arquivo: %s", arquivo))
```


```{r}

# define pallette de cores
purple_orange <- brewer.pal(10, "PuOr")
# drop 2 faintest colors
purple_orange <- purple_orange[-(1:2)]

# criando uma tdm com "term frequency-inverse document frequency".
# The TfIdf score increases by term occurrence but is penalized by the frequency of appearance among all documents.
# From a common sense perspective, if a term appears often it must be important. This attribute is represented by term frequency (i.e. Tf), which is normalized by the length of the document. However, if the term appears in all documents, it is not likely to be insightful. This is captured in the inverse document frequency (i.e. Idf).
tdm <- TermDocumentMatrix(docs, control = list(wordLengths = c(3,10), weighting = weightTfIdf))

# Why would you want to adjust the sparsity of the TDM/DTM?
# TDMs and DTMs are sparse, meaning they contain mostly zeros.
# A good TDM has between 25 and 70 terms. The lower the sparse value, the more terms are kept. The closer it is to 1, the fewer are kept. This value is a percentage cutoff of zeros for each term in the TDM.
tdm <- removeSparseTerms(tdm, 0.9999)
tdm <- as.matrix(tdm)
freq_tdm <- rowSums(tdm)

freq_tdm <- sort(freq_tdm, decreasing = TRUE)[1:20]
freq_tdm <- data.frame(WORD = names(freq_tdm), FREQ = freq_tdm)

# define divisao grafico
par(mfrow = c(1, 2), pty = "s")

# create a wordcloud with purple_orange palette
# docs
wordcloud(docs, max.words = 20, colors = purple_orange)
# freq_tdm
wordcloud(freq_tdm$WORD, freq_tdm$FREQ, max.words = 20, colors = purple_orange)
```

```{r, echo = FALSE}
### gráfico com os termos mais frequentes
p1 <- tfq[1:20,] %>%
   ggplot(aes(x = reorder(WORD, FREQ), y = FREQ)) +
   geom_col() +
   xlab(NULL) +
   coord_flip() +
   theme(panel.background = element_rect(fill='white', colour='gray')) +
   ylab("Freq") + xlab("Palavra")

p2 <- freq_tdm %>%
   ggplot(aes(x = reorder(WORD, FREQ), y = FREQ)) +
   geom_col() +
   xlab(NULL) +
   coord_flip() +
   theme(panel.background = element_rect(fill='white', colour='gray')) +
   ylab("Freq") + xlab("Palavra")

grid.arrange(p1, p2)
```

```{r, echo = FALSE}
# dendogramas

# tdm_df <- as.data.frame(tdm)

# Create tweets_dist
# tdm_dist <- dist(tdm_df)

# Create hc
# hc <- hclust(tdm_dist)

# Plot the dendrogram
# plot(hc)
```

```{r, echo = FALSE}
# Wordcloud de bigramas
wordcloud(bigramas$bigram, bigramas$n, max.words = 20, colors = purple_orange)

# http://dsnotes.com/post/text2vec/
# https://github.com/ropensci/tokenizers

```




