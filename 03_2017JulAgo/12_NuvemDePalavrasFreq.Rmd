---
title: "Palavras frequentes"
output: html_document
params:
  ini: 2016
  fim: 2017
  partido: "PSDB"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

### Critérios informados

```{r, echo=FALSE}
source("..\\02_2017MaiJun\\05_EncodeDecode.R")

# parâmetros
ini <- params$ini
fim <- params$fim
partido <- params$partido

# pacotes
if(!require(tm)) { install.packages('tm') }
if(!require(qdap)) { install.packages('qdap') }
if(!require(RWeka)) { install.packages('RWeka') }

if(!require(tidyverse)) { install.packages('tidyverse') }
if(!require(tidytext)) { install.packages('tidytext') }
if(!require(tidyr)) { install.packages('tidyr') }
if(!require(dplyr)) { install.packages('dplyr') }   

if(!require(wordcloud)) { install.packages('wordcloud') }
if(!require(SnowballC)) { install.packages('SnowballC') }
if(!require(stringr)) { install.packages('stringr') }
if(!require(ggplot2)) { install.packages('ggplot2') }
if(!require(gridExtra)) { install.packages('gridExtra') }

# https://rpubs.com/mlmv/swiftkey


# lê arquivo com todos os discursos
pasta <- "..\\CorporaRDS\\"
arquivo <- paste0("corpora_", partido, "_", ini, "_", fim, "_limpo.rds")
lista <- readRDS(paste0(pasta, arquivo))
docs <- lista[[1]]
tfq  <- lista[[2]]
bigramas <- lista[[3]]

print(sprintf("Partido: %s (%d - %d)", partido, ini, fim))
print(sprintf("Arquivo: %s", arquivo))
```


```{r}

# define pallette de cores
purple_orange <- brewer.pal(10, "PuOr")
# drop 2 faintest colors
purple_orange <- purple_orange[-(1:2)]

# criando uma tdm com "term frequency-inverse document frequency".
# The TfIdf score increases by term occurrence but is penalized by the frequency of appearance among all documents.
# From a common sense perspective, if a term appears often it must be important. This attribute is represented by term frequency (i.e. Tf), which is normalized by the length of the document. However, if the term appears in all documents, it is not likely to be insightful. This is captured in the inverse document frequency (i.e. Idf).
tdm <- TermDocumentMatrix(docs, control = list(wordLengths = c(3,15), weighting = weightTfIdf))

# Why would you want to adjust the sparsity of the TDM/DTM?
# TDMs and DTMs are sparse, meaning they contain mostly zeros.
# A good TDM has between 25 and 70 terms. The lower the sparse value, the more terms are kept. The closer it is to 1, the fewer are kept. This value is a percentage cutoff of zeros for each term in the TDM.
tdm <- removeSparseTerms(tdm, 0.9999)
tdm <- as.matrix(tdm)
freq_tdm <- rowSums(tdm)

freq_tdm <- sort(freq_tdm, decreasing = TRUE)[1:20]
freq_tdm <- data.frame(WORD = names(freq_tdm), FREQ = freq_tdm)

# define divisao grafico
par(mfrow = c(1, 2), pty = "s")

# create a wordcloud with purple_orange palette
# tfq - sem tratamento TfIdf e sparsity
wordcloud(tfq$WORD, tfq$FREQ, max.words = 20, colors = purple_orange)
# freq_tdm - com tratamento TfIdf e sparsity
wordcloud(freq_tdm$WORD, freq_tdm$FREQ, max.words = 20, colors = purple_orange)
```

```{r, echo = FALSE}
### gráfico com os termos mais frequentes
p1 <- tfq[1:20,] %>%
   ggplot(aes(x = reorder(WORD, FREQ), y = FREQ)) +
   geom_col() +
   xlab(NULL) +
   coord_flip() +
   theme(panel.background = element_rect(fill='white', colour='gray')) +
   ylab("Freq") + xlab("Palavra")

p2 <- freq_tdm %>%
   ggplot(aes(x = reorder(WORD, FREQ), y = FREQ)) +
   geom_col() +
   xlab(NULL) +
   coord_flip() +
   theme(panel.background = element_rect(fill='white', colour='gray')) +
   ylab("Freq") + xlab("Palavra")

grid.arrange(p1, p2)
```

```{r, echo = FALSE}
# dendogramas
tfq <- tfq[1:20,]
hc <- hclust( dist(tfq$FREQ) )
plot(hc, labels = tfq$WORD, main = "Contagem bruta", xlab = "Palavras")

hc <- hclust( dist(freq_tdm$FREQ) )
plot(hc, labels = freq_tdm$WORD, main = "Contagem com TfIdf e Sparsity", xlab = "Palavras")

```

```{r, echo = FALSE}
# Wordcloud de bigramas
wordcloud(bigramas$bigram, bigramas$n, max.words = 20, colors = purple_orange)

bigramas <- bigramas[1:20,]
p3 <- bigramas %>%
   ggplot(aes(x = reorder(bigram, n), y = n)) +
   geom_col() +
   xlab(NULL) +
   coord_flip() +
   theme(panel.background = element_rect(fill='white', colour='gray')) +
   ylab("Freq") + xlab("Bigrama")
p3

```

```{r, echo = FALSE}
# Dendogramas de bigramas
hc <- hclust( dist(bigramas$n) )
plot(hc, labels = bigramas$bigram, main = "Contagem bruta", xlab = "Bigramas")

```

A análise de cluster hierárquica usa o conjunto de diferenças para os objetos em cluster. Inicialmente, cada objeto é atribuído ao seu próprio cluster e, em seguida, o algoritmo prossegue iterativamente, em cada etapa, juntando os dois clusters mais semelhantes, continuando até existir apenas um único cluster. Em cada estágio, as distâncias entre clusters são recalculadas pela fórmula de atualização de dissimilaridade de Lance-Williams, de acordo com o método *complete linkage* que encontra clusters similares.

