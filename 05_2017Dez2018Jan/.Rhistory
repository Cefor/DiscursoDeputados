solar300 <- beta0 + beta1*300
solar300
## Verificar o valor de R2
summary(fit2)
summary(fit2)$r.squared
#Regressão Linear
fit3 <- lm(Ozone ~ Wind, data = airquality3)
## coeficientes de Regressão
coeficiente <- fit3$coefficients
beta0 <- coeficiente[1]
beta1 <- coeficiente[2]
beta0
beta1
## Determinando os valores esperados para cada valor de x
#1.5
vento1.5 <- beta0 + beta1*1.5
vento1.5
#3.7
vento3.7 <- beta0 + beta1*3.7
vento3.7
#10
vento10 <- beta0 + beta1*10
vento10
#15.3
vento15.3 <- beta0 + beta1*15.3
vento15.3
#22
vento22 <- beta0 + beta1*22
vento22
eleicoes2014 <- read.csv2('Eleicoes2014.csv')
fit4 <- lm(Nominais ~ Receitas.em.2014, data = eleicoes2014)
summary(fit4)
## Regressão Linear
fit4 <- lm(Nominais ~ Receitas.em.2014, data = eleicoes2014)
summary(fit4)
## Os coeficientes de Regressão
# Pela fórmula
coeficiente <- fit4$coefficients
beta0 <- coeficiente[1]
beta1 <- coeficiente[2]
beta0
beta1
## Gráfico de dispersão e Reta de Regressão
plot(eleicoes2014$Receitas.em.2014, eleicoes2014$Nominais, xlab = "Receita", ylab = "Votos")
abline(fit4)
## Histograma de Resíduos
hist(fit4$residuals, xlab = "Residuos", ylab = "Frequencia", col = rainbow (9))
## Gráfico de resíduos vs valor preditor
#plot(eleicoes2014$Receitas.em.2014, fit4$residuals) #grafico
lmIC <- function(x, Y, vx=NULL, nc=.95){
n <- length(x)
tc <- nc + (1-nc)/2 # tc = t crítico
plot(x, Y , frame=FALSE, pch=21, col="black", bg="lightblue", cex=2)
fit <- lm(Y ~ x)
abline(fit, lwd=2)
beta0 <- coef(fit)[1]
beta1 <- coef(fit)[2]
xVals <- seq(min(x,na.rm=TRUE),
max(x,na.rm=TRUE),
by=(max(x,na.rm=TRUE)-min(x,na.rm=TRUE))/200)
yVals <- beta0 + beta1 * xVals
sigma <- sqrt(sum(fit$residuals^2) / (n-2))
ssx <- sum((x - mean(x))^2)
se1 <- sigma * sqrt(1 / n + (xVals - mean(x))^2 / ssx)
se2 <- sigma * sqrt(1 + 1 / n + (xVals - mean(x))^2 / ssx)
lines(xVals, yVals + qt(tc,n-2) * se1, col="red")
lines(xVals, yVals - qt(tc,n-2) * se1, col="red")
lines(xVals, yVals + qt(tc,n-2) * se2, col="blue")
lines(xVals, yVals - qt(tc,n-2) * se2, col="blue")
if( !is.null(vx) ){
ret <- NULL
yVals <- beta0 + beta1 * vx
se2 <- sigma * sqrt(1 + 1 / n + (vx - mean(x))^2 / ssx)
for(i in 1:length(vx)){
ret <- c(ret, yVals[i],
yVals[i] - qt(tc,n-2) * se2[i],
yVals[i] + qt(tc,n-2) * se2[i])
}
return(matrix(ret, ncol=3, byrow = TRUE,
dimnames=list(c(),c("esperado","Icmin","ICmax"))))
}
}
lmIC(cars$speed, cars$dist)
lmIC(airquality3$Solar.R, airquality3$Ozone)
lmIC(airquality3$Wind, airquality3$Ozone)
lmIC <- function(x, Y, vx=NULL, nc=.95){
n <- length(x)
tc <- nc + (1-nc)/2 # tc = t crítico
plot(x, Y , frame=FALSE, pch=21, col="black", bg="lightblue", cex=2)
fit <- lm(Y ~ x)
abline(fit, lwd=2)
beta0 <- coef(fit)[1]
beta1 <- coef(fit)[2]
xVals <- seq(min(x,na.rm=TRUE),
max(x,na.rm=TRUE),
by=(max(x,na.rm=TRUE)-min(x,na.rm=TRUE))/200)
yVals <- beta0 + beta1 * xVals
sigma <- sqrt(sum(fit$residuals^2) / (n-2))
ssx <- sum((x - mean(x))^2)
se1 <- sigma * sqrt(1 / n + (xVals - mean(x))^2 / ssx)
se2 <- sigma * sqrt(1 + 1 / n + (xVals - mean(x))^2 / ssx)
lines(xVals, yVals + qt(tc,n-2) * se1, col="red")
lines(xVals, yVals - qt(tc,n-2) * se1, col="red")
lines(xVals, yVals + qt(tc,n-2) * se2, col="blue")
lines(xVals, yVals - qt(tc,n-2) * se2, col="blue")
if( !is.null(vx) ){
ret <- NULL
yVals <- beta0 + beta1 * vx
se2 <- sigma * sqrt(1 + 1 / n + (vx - mean(x))^2 / ssx)
for(i in 1:length(vx)){
ret <- c(ret, yVals[i],
yVals[i] - qt(tc,n-2) * se2[i],
yVals[i] + qt(tc,n-2) * se2[i])
}
return(matrix(ret, ncol=3, byrow = TRUE,
dimnames=list(c(),c("esperado","Icmin","ICmax"))))
}
}
## Exercício 1
lmIC(cars$speed, cars$dist)
## Exercíco 2
lmIC(airquality3$Solar.R, airquality3$Ozone)
lmIC(airquality3$Wind, airquality3$Ozone)
### Exercício 3
lmIC(eleicoes2014$Receitas.em.2014, eleicoes2014$Receitas)
eleicoes2014 <- read.csv2('Eleicoes2014.csv')
lmIC(eleicoes2014$Receitas.em.2014, eleicoes2014$Receitas)
lmIC <- function(x, Y, vx=NULL, nc=.95){
n <- length(x)
tc <- nc + (1-nc)/2 # tc = t crítico
plot(x, Y , frame=FALSE, pch=21, col="black", bg="lightblue", cex=2)
fit <- lm(Y ~ x)
abline(fit, lwd=2)
beta0 <- coef(fit)[1]
beta1 <- coef(fit)[2]
xVals <- seq(min(x,na.rm=TRUE),
max(x,na.rm=TRUE),
by=(max(x,na.rm=TRUE)-min(x,na.rm=TRUE))/200)
yVals <- beta0 + beta1 * xVals
sigma <- sqrt(sum(fit$residuals^2) / (n-2))
ssx <- sum((x - mean(x))^2)
se1 <- sigma * sqrt(1 / n + (xVals - mean(x))^2 / ssx)
se2 <- sigma * sqrt(1 + 1 / n + (xVals - mean(x))^2 / ssx)
lines(xVals, yVals + qt(tc,n-2) * se1, col="red")
lines(xVals, yVals - qt(tc,n-2) * se1, col="red")
lines(xVals, yVals + qt(tc,n-2) * se2, col="blue")
lines(xVals, yVals - qt(tc,n-2) * se2, col="blue")
if( !is.null(vx) ){
ret <- NULL
yVals <- beta0 + beta1 * vx
se2 <- sigma * sqrt(1 + 1 / n + (vx - mean(x))^2 / ssx)
for(i in 1:length(vx)){
ret <- c(ret, yVals[i],
yVals[i] - qt(tc,n-2) * se2[i],
yVals[i] + qt(tc,n-2) * se2[i])
}
return(matrix(ret, ncol=3, byrow = TRUE,
dimnames=list(c(),c("esperado","Icmin","ICmax"))))
}
}
lmIC(eleicoes2014$Receitas.em.2014, eleicoes2014$Receitas)
View(eleicoes2014)
eleicoes2014$Receitas.em.2014
View(eleicoes2014)
eleicoes2014 <- read.csv('Eleicoes2014.csv')
eleicoes2014 <- read.csv('Eleicoes2014.csv', sep=";")
? freq_terms
? VCorpus
# pacotes
if(!require(tm)) { install.packages('tm') }
? VCorpus
? unnest_tokens
if(!require(tidyverse)) { install.packages('tidyverse') }
if(!require(tidytext)) { install.packages('tidytext') }
if(!require(tidyr)) { install.packages('tidyr') }
if(!require(dplyr)) { install.packages('dplyr') }
? unnest_tokens
? bigram
getwd()
readRDS?
)
? readRDS
? RDS
? unnest_tokens
library(tm)
? unnest_tokens
library(dplyr)
? unnest_tokens
library(qdap)
? unnest_tokens
? unnest_tokens()
library(tidyverse)
? unnest_tokens()
library(tidytext)
? unnest_tokens()
? VCorpus
setwd("F:/_Pesquisa/PosDoc/_Github/05_2017Dez2018Jan")
library(stringr)
source("22_TesteHipotese.R")
ano <- 2016
PT <- readRDS(paste0("..\\CorpusRDS\\corpus_PT_", ano, "_", ano, "_limpo.rds"))
PSDB <- readRDS(paste0("..\\CorpusRDS\\corpus_PSDB_", ano, "_", ano, "_limpo.rds"))
PMDB <- readRDS(paste0("..\\CorpusRDS\\corpus_PMDB_", ano, "_", ano, "_limpo.rds"))
PSOL <- readRDS(paste0("..\\CorpusRDS\\corpus_PSOL_", ano, "_", ano, "_limpo.rds"))
PCDOB <- readRDS(paste0("..\\CorpusRDS\\corpus_PCDOB_", ano, "_", ano, "_limpo.rds"))
PTB <- readRDS(paste0("..\\CorpusRDS\\corpus_PTB_", ano, "_", ano, "_limpo.rds"))
##################################################
# Medida de similaridade e homogeneidade de corpus
##################################################
# Executa teste qui-quadrado para avaliação de similaridade
# Aqui a medida de similaridade é efetuada em corpus homogêneos (discurso parlamentar)
# Rejeitar Ho (p < 0.05) significa dissimilaridade
n <- 500
tfq1 <- PT$tfq
tfq2 <- PSDB$tfq
ntokens1 <- PT$ntokens
ntokens2 <- PSDB$ntokens
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- PT$bigramas
tfq2 <- PSDB$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- PT$tfq
tfq2 <- PMDB$tfq
ntokens1 <- PT$ntokens
ntokens2 <- PMDB$ntokens
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- PT$bigramas
tfq2 <- PMDB$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- PT$tfq
tfq2 <- PSOL$tfq
ntokens1 <- PT$ntokens
ntokens2 <- PSOL$ntokens
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- PT$bigramas
tfq2 <- PSOL$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- PSDB$tfq
tfq2 <- PSOL$tfq
ntokens1 <- PSDB$ntokens
ntokens2 <- PSOL$ntokens
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- PSDB$bigramas
tfq2 <- PSOL$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
? matrix
mp <- matrix(
c("PT", "PSDB", "PT", "PMDB", "PT", "PSOL", "PT", "PCDOB", "PT", "PTB",
"PSDB", "PMDB", "PSDB", "PSOL", "PSDB", "PCDOB", "PSDB", "PTB",
"PMDB", "PSOL", "PMDB", "PCDOB", "PMDB", "PTB",
"PSOL", "PCDOB", "PSOL", "PTB",
"PCDOB", "PTB"),
ncol = 2,
byrow = TRUE
)
mp
nrow(mp)
mp[1,1]
mp[1,1]$tfq
[mp[1,1]]$tfq
{mp[1,1]}$tfq
? list
lp <- list(PT, PSDB, PMDB, PSOL, PCDOB, PTB)
lp[[1]]
names(lp) <- c("PT", "PSDB", "PMDB", "PSOL", "PCDOB", "PTB")
lp <- list(PT, PSDB, PMDB, PSOL, PCDOB, PTB)
names(lp) <- c("PT", "PSDB", "PMDB", "PSOL", "PCDOB", "PTB")
# partidos
# PT, PSDB, PMDB, PSOL, PCDOB, PTB
mp <- matrix(
c("PT", "PSDB", "PT", "PMDB", "PT", "PSOL", "PT", "PCDOB", "PT", "PTB",
"PSDB", "PMDB", "PSDB", "PSOL", "PSDB", "PCDOB", "PSDB", "PTB",
"PMDB", "PSOL", "PMDB", "PCDOB", "PMDB", "PTB",
"PSOL", "PCDOB", "PSOL", "PTB",
"PCDOB", "PTB"),
ncol = 2,
byrow = TRUE
)
n <- 500
df <- NULL
for(i in 1:nrow(mp)){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
X2 <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
df <- rbind(df, data.frame(partido1=mp[i,1], partido2=mp[i,2], X2=X2[1], p=X2[2]))
}
View(df)
n <- 500
df <- NULL
for(i in 1:nrow(mp)){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
uni <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
big <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
df <- rbind(df, data.frame(partido1=mp[i,1], partido2=mp[i,2],
uni_X2=uni[1], uni_p=X2[2],
big_X2=uni[1], big_p=X2[2]))
}
View(df)
n <- 500
df <- NULL
for(i in 1:nrow(mp)){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
uni <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
if(uni[2] < 0.05) uni <- "rejeita Ho"
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
big <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
if(big[2] < 0.05) big <- "rejeita Ho"
df <- rbind(df, data.frame(partido1=mp[i,1], partido2=mp[i,2],
unigrama=uni, bigrama=big))
}
View(df)
n <- 500
df <- NULL
for(i in 1:nrow(mp)){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
uni <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
if(uni[2] < 0.05) uni <- "rejeita Ho"
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
big <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
if(big[2] < 0.05) big <- "rejeita Ho"
df <- rbind(df, data.frame(partido1=mp[i,1], partido2=mp[i,2],
unigrama=uni, bigrama=big))
}
n <- 500
df <- NULL
for(i in 1:nrow(mp)){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
uni <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
big <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
df <- rbind(df, data.frame(partido1=mp[i,1], partido2=mp[i,2],
uni_X2=uni[1], uni_p=X2[2],
big_X2=uni[1], big_p=X2[2]))
}
View(df)
n <- 500
df <- NULL
for(i in 1:nrow(mp)){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
uni <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
if(uni[2] < 0.05) uni <- "rejeita Ho"
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
big <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
if(big[2] < 0.05) big <- "rejeita Ho"
df <- rbind(df, data.frame(partido1=mp[i,1], partido2=mp[i,2],
unigrama=uni, bigrama=big))
}
View(df)
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
uni <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
uni
uni[2] < 0.05
uni <- "rejeita Ho"
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
big <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
big
big[2] < 0.05
big <- "rejeita Ho"
data.frame(partido1=mp[i,1], partido2=mp[i,2],
unigrama=uni, bigrama=big)
mp
mp[i,1]]
mp[i,1]
mp[i,2]
i = 6
mp[i,2]
mp[i,1]
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
uni <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
uni
uni[1]
uni[2]
n <- 500
df <- NULL
for(i in 1:nrow(mp)){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
uni <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
big <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
df <- rbind(df, data.frame(partido1=mp[i,1], partido2=mp[i,2],
uni_X2=uni[1], uni_p=uni[2],
big_X2=big[1], big_p=big[2]))
}
View(df)
n <- 500
df <- NULL
for(i in 1:nrow(mp)){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
uni <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
uniHo <- 'aceita Ho'
if(uni[2] < 0.05) uniHo <- 'rejeita Ho'
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
big <- corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
bigHo <- 'aceita Ho'
if(big[2] < 0.05) bigHo <- 'rejeita Ho'
df <- rbind(df, data.frame(partido1=mp[i,1], partido2=mp[i,2],
uni_X2=uni[1], uni_p=uni[2], uniHo = uniHo,
big_X2=big[1], big_p=big[2], bigHo = bigHo))
}
View(df)
write.csv(df,"Tabela57.csv")
corpus_similaridade <- function(tfq1, tfq2, ntokens1, ntokens2, n = 500, ver_temas=FALSE){
# garante que os nomes das colunas sejam WORD e FREQ
# mesmo quando são enviados bigramas
names(tfq1) <- c("WORD", "FREQ")
names(tfq2) <- c("WORD", "FREQ")
words <- tfq1$WORD[1:n]
words <- words[words %in% tfq2$WORD]
tfq1 <- tfq1[tfq1$WORD %in% words, ]
tfq2 <- tfq2[tfq2$WORD %in% words, ]
tfq1 <- tfq1[order(tfq1$WORD), ]
tfq2 <- tfq2[order(tfq2$WORD), ]
# ow1: freq. observada da palavra no corpus 1
# ow2: freq. observada da palavra no corpus 2
df <- data.frame(temas=tfq1$WORD, ow1 = tfq1$FREQ, ow2 = tfq2$FREQ)
if(ver_temas) print(df[1:10,])
# ew1: valor esperado da palavra no corpus 1
df$ew1 <- (ntokens1 * (df$ow1 + df$ow2)) / (ntokens1 + ntokens2)
# ew2: valor esperado da palavra no corpus 2
df$ew2 <- (ntokens2 * (df$ow1 + df$ow2)) / (ntokens1 + ntokens2)
X2 <- sum((df$ow1 - df$ew1)^2 / df$ew1) + sum((df$ow2 - df$ew2)^2 / df$ew2)
gl <- length(words) - 1
c(X2, pchisq(X2, gl, lower.tail=FALSE))
}
li <- c(6,13)
for(i in li){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n)
}
li <- c(6,13)
for(i in li){
tfq1 <- lp[[mp[i,1]]]$tfq
tfq2 <- lp[[mp[i,2]]]$tfq
ntokens1 <- lp[[mp[i,1]]]$ntokens
ntokens2 <- lp[[mp[i,2]]]$ntokens
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n, TRUE)
tfq1 <- lp[[mp[i,1]]]$bigramas
tfq2 <- lp[[mp[i,2]]]$bigramas
ntokens1 <- nrow(tfq1)
ntokens2 <- nrow(tfq2)
corpus_similaridade(tfq1, tfq2, ntokens1, ntokens2, n, TRUE)
}
